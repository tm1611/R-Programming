---
title: "4. Writing Functions in R"
author: "Timo Meiendresch"
knit: (function(input_file, encoding) {
  out_dir <- 'html_files';
  rmarkdown::render(input_file,
  encoding=encoding,
  output_file=file.path(dirname(input_file), out_dir, 'Functions in R.html'))})
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=F}
library(purrr)
```

# Functions in R
Recall the elements of a function in R: 

- formals
- body
- environment



```{r}
# typical function definition
add <- function(x, y=1){
  x+y
}

# 
args(add)
formals(add)
body(add)
environment(add)
```

- Last expression evaluated in a function is the return value
- `return(value)` forces the function to stop execution and return value 
- anonymous functions: functions without a name

```{r}
# anonymous function
(function(x){x+1})(2)
```

Three parts of a function:

- arguments
- body
- environment 

### Environments
Scoping describes how R looks up values by name. If a name isn't defined inside a function, R will look one level up.

```{r}
x <- 2
g <- function(){
  y <- 1
  c(x,y)
}

g()

# 


```

Scoping describes where, not when, to look for a value

```{r}
# depends on environment 
f <- function() x
x <- 15
f()

# x in env is change
x <- 20
f()
```

- When you call a function, a new environment is made for the function to do its work.
- New env is populated with the argument values
- Objects are looked for first in this environment

### Data Structures
```{r}
typeof(letters)
typeof(1:10)
typeof(NULL)
length(NULL)
typeof(NA)
length(NA)
```

- Missing values are contagious!

Lists:

- Useful because they can contain heterogeneous objects
- complicated return objects are lists, ie from lm()

### for loops
Parts of a for loop

- sequence
- body
- 

```{r}
# looping over cols in a df
df <- data.frame(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

for (i in 1:ncol(df)) {
  print(median(df[[i]]))
}

```

Moving forward, we'll see a safer way to generate the sequence using `seq_along()` and saving the output instead of printing it. 

```{r}
# Replace the 1:ncol(df) sequence
for (i in seq_along(df)) {
  print(median(df[[i]]))
}

# Create an empty data frame
empty_df <- data.frame()

# Repeat for loop to verify there is no error
for (i in seq_along(empty_df)) {
  print(median(empty_df[[i]]))
}

# Create new double vector: output
output <- vector(mode = "double", ncol(df))

# Alter the loop
for (i in seq_along(df)) {
  # Change code to store result in output
  output[[i]] <- median(df[[i]])
}

# Print output
print(output)
```

# When and how you should write a function

### When?

- Copy-paste rule of thumb: Whenever you have copied-and-pasted twice, it's time to write a function

```{r}
# Define example vector x
x <- c(1:10, NA)

# Define rng
rng <- range(x, na.rm=TRUE)

# Rewrite this snippet to refer to the elements of rng
(x - min(x, na.rm = TRUE)) /
  (rng[2] - rng[1])

# Use this in function
rescale01 <- function(x) {
  rng <- range(x, na.rm=TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}

# Test your function, call rescale01 using the vector x as the argument
rescale01(x)
```

### How?

1. Start with a simple problem. It is helpful if you know the answer.
2. Get a working snipped of code.
3. Rewrite to use temporary variables. Rewrite for clarity. Snippet is the body of the function. Temporary arguments are then the inputs
4. Turn into a function

```{r}
# Define example vectors x and y
x <- c( 1, 2, NA, 3, NA)
y <- c(NA, 3, NA, 3,  4)

# Count how many elements are missing in both x and y
sum(is.na(x) & is.na(y))

# Turn this snippet into a function: both_na()
both_na <- function(x,y){
  sum(is.na(x) & is.na(y))
}
```

Note that this function only works in cases where x and y have the same length. 

### How to write a good function?
Function is

- correct
- understandable
- readable for humans and computers
- correct + understandable = obviously correct

Naming the function as a verb which describes what it does is a good start. In addition, we should not use function names that are already taken nor use variables which have already a meaning (e.g. `T` or `c`).

```{r}
# Altered mean_ci function
mean_ci <- function(x, level = 0.95) {
  if (length(x) == 0) {
    warning("`x` was empty", 
    interval <- c(-Inf, Inf))
    return(interval)
  } else {
    se <- sd(x) / sqrt(length(x))
    alpha <- 1 - level
    mean(x) + se * qnorm(c(alpha / 2, 1 - alpha / 2))
  }
}

mean_ci(numeric(0))
mean_ci(x)

# replace_missings function
replace_missings <- function(x, replacement) {
  x[is.na(x)] <- replacement
  cat(sum(is.na(x)), replacement, "\n")
  x
}

replace_missings(x, 0)

# A few more tweaks...
replace_missings <- function(x, replacement) {
  is_miss <- is.na(x)
  x[is_miss] <- replacement
  
  # Rewrite to use message()
  message(sum(is_miss), " missings replaced by the value ", replacement)
  x
}

replace_missings(x, replacement=10)

```

# Functional Programming

- Alternatives to the for-loop.

1. Rely on domain knowledge
2. Use variables
3. Extract out common code

```{r}
# Initialize output vector
output <- numeric(ncol(df))

for (i in seq_along(df)){
  output[i] <- median(df[[i]])
}

# turn this code into col_median()
col_median <- function(df){
  output <- numeric(ncol(df))
  for (i in seq_along(df)){
    output[[i]] <- median(df[[i]])
  }
  output
}

col_median(df)

# change to col_mean()
col_mean <- function(df) {
  output <- numeric(ncol(df))
  for (i in seq_along(df)) {
    output[[i]] <- mean(df[[i]])
  }
  output
}

# Define col_sd() function
col_sd <- function(df) {
  output <- numeric(length(df))
  for (i in seq_along(df)) {
    output[[i]] <- sd(df[[i]])
  }
  output
}

```

We just copied and paste the function `col_median` two times! This is a sign that we need to write a function! We start with a simple example first...

```{r}
# Add a second argument called power
f <- function(x, power) {
    # Edit the body to return absolute deviations raised to power
    (abs(x - mean(x)))^power
}
```

Note that functions can be arguments too!

```{r}
# col_sumamry function
col_summary <- function(df, fun){
  output <- numeric(length(df))
  for (i in seq_along(df)){
    output[i] <- fun(df[[i]])
  }
  output
}

col_summary(df, fun = median)
col_summary(df, fun = mean)
col_summary(df, fun = sd)

# Find the column IQRs using col_summary()
col_summary(df, fun = IQR)

```

### Introducing purrr
Passing functions as arguments is a principle that we've already seen with the apply family functions. Now, we want to introduce into a whole family of functions with similar workings. The `map()` functions in the `purrr` package.

Every map functions works the same way:
```r
map_dbl(.x, .f, ...)
```

1. Loop over a vector .x
2. Do something to each element .f
3. Return the results

There is one function for each type of vector:

- `map()` returns a list
- `map_dbl()` returns a double vector
- `map_lgl()` returns a logical vector
- `map_int()` returns a integer vector
- `map_chr()` returns a character vector

Now, let's use `map_dbl()` like we have used our summary function before:

```{r}
# Use map_dbl() to find column means
map_dbl(df, mean)

# Use map_dbl() to column medians
map_dbl(df, median)

# Use map_dbl() to find column standard deviations
map_dbl(df, sd)
```

Check the type of an individual output (e.g. of a dataframe) to determine which `map_` funciton is appropriate. 

### Shortcuts for specifying .f

- Using `~`to define an anonymous function on the fly

Data that will be used are a subset of the `mtcars` data.

```{r}
cyl <- split(mtcars, mtcars$cyl)
str(cyl)
head(cyl[[1]])
```

The objective is to fit a regression to each of the data frames in cyl and quantify the relationshiop between mpg and wt. Focus on slopes

```{r}
# structure of cyl
str(cyl)

# first element into four_cyls
four_cyls <- cyl[[1]]

# linear regression of mpg on wt using four_cyls
lm(mpg ~ wt, data=four_cyls)

# Rewrite to call an anonymous function
map(cyl, function(df) lm(mpg ~ wt, df))

# Rewrite to use the formula shortcut instead
map(cyl, ~lm(mpg ~ wt, data = .))

# Save the result from the previous exercise to the variable models
models <- map(cyl, ~ lm(mpg ~ wt, data = .))

# Use map and coef to get the coefficients for each model: coefs
coefs <- map(models, coef)

# Use string shortcut to extract the wt coefficient 
map(coefs, "wt")

# pull out the second element
map_dbl(coefs, 2)

```
Using the pipe operator:

```{r}
# Define models 
models <- mtcars %>% 
  split(mtcars$cyl) %>%
  map(~ lm(mpg ~ wt, data = .))

# Rewrite to be a single command using pipes 
summaries <- models %>%
  map(summary) %>%
  map_dbl("r.squared")
```

# Advanced inputs and outputs

- map functions fail hard if they fail
- use `safely(log)` for example 

Other adverbs for unusual output in `purrr`:
- `safely()`
- `possibly()`
- `quietly()`

```{r}
# safe_log
safe_log <- safely(log)
safe_log(-1)
safe_log("a")

# Create safe_readLines()
safe_readLines <- safely(readLines)

# Call on "http://example.org"
example_lines <- safe_readLines("http://example.org")
example_lines

# Call on "http://asdfasdasdkfjlda"
nonsense_lines <- safe_readLines("http://asdfasdasdkfjlda")
nonsense_lines
``` 


```{r}
urls <- list(
  example = "http://example.org",
  rproj = "http://www.r-project.org",
  asdf = "http://asdfasdasdkfjlda"
)

# Define safe_readLines()
safe_readLines <- safely(readLines)

# Use the safe_readLines() function with map(): html
html <- map(urls, safe_readLines)

# Call str() on html
str(html)

# Extract the result from one of the successful elements
head(html[["example"]]$result)

# Extract the error from the element that was unsuccessful
html[["asdf"]][["error"]]

```

```{r}
# Examine the structure of transpose(html)
str(transpose(html))

# Extract the results: res
res <- transpose(html)[["result"]]

# Extract the errors: errs
errs <- transpose(html)[["error"]]

# Create a logical vector is_ok
is_ok <- map_lgl(errs, is_null)

# Extract the successful results
#head(res[is_ok])

# Find the URLs that were unsuccessful
urls[!is_ok]
```

### Mapping over multiple args

```{r}
# rnorm(5)
# rnorm(10)
# rnorm(20)

# using map:
map(list(5,10,20), rnorm)

# rnorm(5, mean = 1)
# rnorm(10, mean = 5)
# rnorm(20, mean = 10)

# using map2
str(map2(list(5, 10, 20), list(1, 5, 10), rnorm))
```

Even more arguments? Use `pmap()` function to iterate over many arguments. 

```{r}
my_list <- pmap(list(n =    list(5, 10, 20),
          mean = list(1, 5, 10),
          sd =   list(0.1, 0.5, 0.1)), rnorm)

str(my_list)
```

Use `invoke_map()` function to iterate over functions (i.e. different distribution functions here). 

```{r}
my_list <- invoke_map(list(rnorm, runif, rexp), n = 5)
str(my_list)

# Define list of functions
funs <- list("rnorm", "runif", "rexp")

# Parameter list for rnorm()
rnorm_params <- list(mean = 10)

# Add a min element with value 0 and max element with value 5
runif_params <- list(min = 0, max = 5)

# Add a rate element with value 5
rexp_params <- list(rate = 5)

# Define params for each function
params <- list(
  rnorm_params,
  runif_params,
  rexp_params
)

# Call invoke_map() on funs supplying params and setting n to 5
invoke_map(funs, params, n = 5)

```

In summary of mapping over many arguments:
- `map2()` - iterate over two arguments
- `pmap()` - iterate over functions and arguments
- `invoke_map()` - iterate over functions and arguments 


### Maps with side effects
Side effects: 

- Describe things that happen beyond the results of a function
- Examples include: printing output, plotting and saving files to disk

```{r}
x <- list(1, "a", 3)

# print side effect
x %>% 
  walk(print)

library(ggplot2)
plots <- cyl %>% 
  map(~ ggplot(., aes(mpg, wt)) + geom_point())

paths <- paste0(names(plots), ".pdf")

# following code saves as pdf 
#walk2(paths, plots, ggsave)

# walk() in a pipeline
lengths <- x %>% 
  walk(print) %>% 
  map_dbl(length)

lengths
```

- Using `walk` and `invoke_map` altogether

```{r}
# Define list of functions
funs <- list(Normal = "rnorm", Uniform = "runif", Exp = "rexp")

# Define params
params <- list(
  Normal = list(mean = 10),
  Uniform = list(min = 0, max = 5),
  Exp = list(rate = 5)
)

# Assign the simulated samples to sims
sims <- invoke_map(funs, params, n = 50)

# Use walk() to make a histogram of each element in sims
walk(sims, hist)
```


- Use walk2() to vary two arguments

```{r}
# Reasonable breaks for each sample
breaks_list <- list(
  Normal = seq(6, 16, 0.5),
  Uniform = seq(0,5, 0.25),
  Exp = seq(0, 1.5, 0.1)
)

# Use walk2() to make histograms with the right breaks
walk2(sims, breaks_list, hist)
```


```{r}
# find_breaks()
find_breaks <- function(x){
  rng <- range(x, na.rm = TRUE)
  seq(rng[1], rng[2], length.out = 30)
}

# Call find_breaks() on sims[[1]]
find_breaks(sims[[1]])

# Use map() to iterate find_breaks() over sims
nice_breaks <- map(sims, find_breaks)

# Use nice_breaks as the second argument to walk2()
walk2(sims, nice_breaks, hist)

# Increase sample size to 1000
sims <- invoke_map(funs, params, n = 1000)

# Compute nice_breaks (don't change this)
nice_breaks <- map(sims, find_breaks)

# Create a vector nice_titles
nice_titles <- c("Normal(10, 1)", "Uniform(0, 5)", "Exp(5)")

# Use pwalk() instead of walk2()
pwalk(.l = list(x=sims, breaks = nice_breaks, main=nice_titles), .f=hist, xlab= "")

# Pipe this along to map(), using summary() as .f
sims %>%
  walk(hist) %>%
  map(summary)

```

# Robust Functions
Easy to use and reliable functions.

Three main problems:

- Type-unstable functions
- Non-standard evaluation
- Hidden arguments 

Throwing errors:

- `stopifnot(is.character(x))`: Check if right arguments
- Using `stop()` with if condition 

```r
if (condition) {
  stop("Error", call. = FALSE)
}

# example
if (!is.character(x)){
  stop("`x` should be a character vector", call. = FALSE)
}
```

```{r, eval = FALSE}
# Define troublesome x and y
x <- c(NA, NA, NA)
y <- c( 1, NA, NA, NA)

both_na <- function(x, y) {
  # Add stopifnot() to check length of x and y
  stopifnot( length(x) == length(y) )
  sum(is.na(x) & is.na(y))
}

# Call both_na() on x and y
both_na(x, y)
```

Using `stop()` instead of `stopifnot()` allows to specify a more informative error message.

```{r, eval = FALSE}
# alternative both_na function
both_na <- function(x, y) {
  # Replace condition with logical
  if ( !(length(x) == length(y)) ) {
    # Replace "Error" with better message
    stop("x and y must have the same length", call. = FALSE)
  }  
  
  sum(is.na(x) & is.na(y))
}

# Call both_na() 
both_na(x, y)
```

### Unstable types

- type-inconsistent: type of the return object depends on the input
- surprises occur when you've used a type-inconsistent function inside your own function
- sometimes lead to hard to decipher error messages

```{r}
# example
df[1,]
```

In general, this should return the first row of the dataframe. But if `df` has only one col, then it returns a vector. Hence, sometimes it returns a `data.frame` and sometimes a `vector`.

Problems occur, when such a behavior is not detected (i.e. within functions).

Note that `[` is a common source of surprises.

Two common solutions for [:

- Use `drop = FALSE:df[x, , drop = FALSE]`
- subset the data frame like a list: `df[x]`

Own functions should be written type-stable to avoid such problems. 

- Be aware of type-unstable functions (`[, sapply,...`). 
- Avoid using type-inconsistent functions inside your own functions. 
- Building a vocabulary of type-consistent functions may help.

```{r}
df <- data.frame(
  a = 1L,
  b = 1.5,
  y = Sys.time(),
  z = ordered(1)
)

A <- sapply(df[1:4], class) 
B <- sapply(df[3:4], class)
```

In this case, A is a list and B a matrix. We will now substitute sapply with `map()` which always returns a list or ...

```{r}
# sapply calls
A <- sapply(df[1:4], class) 
B <- sapply(df[3:4], class)
C <- sapply(df[1:2], class) 

# Demonstrate type inconsistency
str(A)
str(B)
str(C)

# Use map() to define X, Y and Z
X <- map(df[1:4], class)
Y <- map(df[3:4], class)
Z <- map(df[1:2], class)

# Use str() to check type consistency
str(X)
str(Y)
str(Z)

# type-consistent solution
col_classes <- function(df) {
  class_list <- map(df, class)
  map_chr(class_list, 1)
}

# Check that our new function is type consistent
df %>% col_classes() %>% str()
df[3:4] %>% col_classes() %>% str()
df[1:2] %>% col_classes() %>% str()

```

Alternatively, fail early if something goes wrong

```{r, eval=FALSE}
col_classes <- function(df) {
  class_list <- map(df, class)
  # Add a check that no element of class_list has length > 1
  if ( any(map_dbl(class_list, length) > 1) ) {
    stop("Some columns have more than one class", call. = FALSE)
  }
  # Use flatten_chr() to return a character vector
  flatten_chr(class_list)
}

# Check that our new function is type consistent
df %>% col_classes() %>% str()
df[3:4] %>% col_classes() %>% str()
df[1:2] %>% col_classes() %>% str()
```

### Non-standard evaluation
Source of surprises are functions which don't use the usual lookup rules for variables. Examples are 

- `subset()`
- `filter()`

They save a lot of typing but sometimes are acting in a unforeseen way, when used within other functions. Either avoid using non-standard evaluation functions inside your funcitons or learn the surprising cases and protect against them.

```{r}
library(dplyr)

big_x <- function(df, threshold) {
  dplyr::filter(df, x > threshold)
}

head(big_x(diamonds, 7))
```

Hadley's vignette on [non-standard evaluation](http://rpubs.com/hadley/157957).

We want the following in our next function: 

- dataframe must contain variable x
- dataframe must not contain variable threshold

```r
big_x <- function(df, threshold) {
  # Write a check for x not being in df
  if ( !any("x" == colnames(df)) ){
    stop("df must contain variable called x", .call = FALSE)
  }
  # Write a check for threshold being in df
  if (any("threshold" == colnames(df))){
    stop("df must not contain variable called threshold")
  }
  dplyr::filter(df, x > threshold)
}
```

### Hidden arguments

1. Their output only depends on their inputs
2. They don't affect the outside world except through their return value.

- Hidden arguments are funtion inputs that may be different for different users or sessions
- common example: arguments defaults that depend on global options

```{r}
# viewing global options
head(options(), 3)

# specific global options
getOption("digits")

# change to 5
options(digits = 5)
getOption("digits")

# change back to default
options(digits = 7)
getOption("digits")
```

- Return value of a function should never depend on a global option
- Side effects however may be controlled by global options

```{r}
# This is the default behavior
options(stringsAsFactors = TRUE)

# load pools
pools <- read.csv("https://assets.datacamp.com/production/repositories/182/datasets/0badb39b50c7daf000698efbca476716db7c1a6f/swimming_pools.csv")

# Examine the structure of pools
str(pools)

# Change the global stringsAsFactors option to FALSE
options(stringsAsFactors = FALSE)

# load pools again
pools2 <- read.csv("https://assets.datacamp.com/production/repositories/182/datasets/0badb39b50c7daf000698efbca476716db7c1a6f/swimming_pools.csv")

# Examine the structure of pools2
str(pools2)

# restore default 
options(stringsAsFactors = TRUE)
```

Wrap up:

**Writing functions:**

- If you have copy-and-pasted two times, it's time to write a function
- Solve the simple problem outside, before writing the function
- A good function is both correct and understandable

**Functional Programming**

- Use functions that write the correct for loops for you. Abstract away the pattern, so you can focus on the data and actions
- Solve iteration problems more easily and have more understandable code.

**Unusual Inputs and Outputs:**

- Deal with failure using `safely()`
- Iterate over two or more arguments 
- Iterate funcitons for their side effects

**Write functions taht don't suprise**

- Use stop() and stopifnot() to fail early
- Avoid using type-inconsistent functions in your own functions
- Avoid non-standard evaluation functions in your own functions
- Never rely on global options for computational details

However, focus on solving the problme that you're working on and never feel bad about using a for loop. Get a funciton that works right, for the easiest 80% of the problem. In time, you'll learn how to get to 99% wiht minimal extra effort. Concise and elegant code is something to strive towards!








